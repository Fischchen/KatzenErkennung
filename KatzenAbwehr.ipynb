{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KatzenAbwehr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEFT9Bjvg8k5hwEZz9ZR59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fischchen/KatzenErkennung/blob/main/KatzenAbwehr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3_Y6ceddoBX"
      },
      "source": [
        "# Prepare dataset\n",
        "## Prepares dataset by renaming, sorting and alterating images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzdneKg-ajmb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "7fcd7fc9-34d4-49dc-9843-986f94dee835"
      },
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andrewmvd/dog-and-cat-detection\n",
        "!unzip -q dog-and-cat-detection.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1f7b080-9137-4727-bb5b-406a39e28be4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c1f7b080-9137-4727-bb5b-406a39e28be4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading dog-and-cat-detection.zip to /content\n",
            " 99% 1.02G/1.03G [00:15<00:00, 73.8MB/s]\n",
            "100% 1.03G/1.03G [00:15<00:00, 69.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtyxJwejqam4"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "\n",
        "\n",
        "all_xmls = os.listdir(\"./annotations\")\n",
        "imagePath=\"./images\"\n",
        "annotationsPath=\"./annotations\"\n",
        "for xml_file in all_xmls:\n",
        "  image=\"\"\n",
        "  imageType=\"\"\n",
        "  if(True):\n",
        "    content = open(\"./annotations/\"+xml_file,\"r\")\n",
        "    tree = ET.parse(content)\n",
        "    root = tree.getroot()\n",
        "    for name in root.iter(\"filename\"):\n",
        "      #print(name.text)\n",
        "      image=name.text\n",
        "    for image_Type in root.iter(\"name\"):\n",
        "      #print(image_Type.text)\n",
        "      imageType = image_Type.text\n",
        "    if (imageType==\"dog\"):\n",
        "      oldname = image\n",
        "      newname = oldname.replace(\"Cats\",\"Dogs\")\n",
        "      try:\n",
        "        os.rename(imagePath+\"/\"+image,imagePath+\"/\"+newname)\n",
        "      except:\n",
        "        pass\n",
        "      oldXMLName = xml_file\n",
        "      newXMLName = oldXMLName.replace(\"Cats\",\"Dogs\")\n",
        "      content.close()\n",
        "      os.rename(annotationsPath+\"/\"+oldXMLName,annotationsPath+\"/\"+newXMLName)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lBnT7HveU8q",
        "outputId": "190a9327-3f93-4a93-d23d-dfb8b72c6381"
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "from tqdm import tqdm_notebook\n",
        "import os\n",
        "import threading\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "all_images = os.listdir(\"./images/\")\n",
        "pbar = tqdm(total=len(all_images))\n",
        "def convertImage(image):\n",
        "    pbar.set_description(f\"Processing {image}\")\n",
        "    imageToProcces = Image.open(\"./images/\"+image)\n",
        "    os.remove(\"./images/\"+image)\n",
        "    newImage = imageToProcces.convert(\"RGBA\")\n",
        "    newImage.save(\"./images/\"+image.replace(\"jpg\",\"png\"))\n",
        "    pbar.update(1)\n",
        "\n",
        "for image in all_images:\n",
        "  x = threading.Thread(target=convertImage,args=(image,))\n",
        "  x.start()\n",
        "\n",
        "print(f\"\\nConverted: {len(all_images)} images to png\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Dogs_Test679.png:  99%|█████████▊| 3635/3686 [04:34<00:03, 16.81it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Converted: 3686 images to png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rProcessing Cats_Test2544.png:  99%|█████████▊| 3636/3686 [04:34<00:02, 16.81it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P64Fy6oBsbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3b1acb-8184-43be-92af-ae442143f794"
      },
      "source": [
        "from scipy.io import savemat\n",
        "import xml.etree.ElementTree as ET\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "def extract_mat_contents(annot_directory):\n",
        "\n",
        "    content = open(\"./annotations/\"+annot_directory,\"r\")\n",
        "    tree = ET.parse(content)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for name in root.iter(\"xmin\"):\n",
        "        x1 = int(name.text)\n",
        "    for name in root.iter(\"ymin\"):\n",
        "        y1 = int(name.text)\n",
        "    for name in root.iter(\"xmax\"):\n",
        "        x2 = int(name.text)\n",
        "    for name in root.iter(\"ymax\"):\n",
        "        y2 = int(name.text)\n",
        "    # os.close(content)\n",
        "    content.close()\n",
        "    # Get the height and width for our image\n",
        "\n",
        "    # Get the bounding box co-ordinates\n",
        "    \n",
        "    save_touple = (x1, y1, x2, y2)\n",
        "    toSave = {\"box_coord\": save_touple}\n",
        "    os.remove(\"./annotations/\"+annot_directory)\n",
        "    savemat(\"./annotations/\"+annot_directory.replace(\".xml\",\".mat\"),toSave)\n",
        "\n",
        "    # Return the extracted attributes\n",
        "    return\n",
        "\n",
        "\n",
        "all_files = os.listdir(\"./annotations\")\n",
        "for file in all_files:\n",
        "  extract_mat_contents(file)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Cats_Test2544.png: 100%|█████████▉| 3683/3686 [04:36<00:00, 35.19it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dnVrAU9gvLP",
        "outputId": "83875fb8-5a74-4167-a59b-d772384e1215"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "def distribute_annotations_train_validation_split(validation_size=0.2):\n",
        "\n",
        "    all_images = os.listdir(\"./annotations\")\n",
        "   #print(all_images)\n",
        "    random.shuffle(all_images)\n",
        "\n",
        "    all_dogs = list(filter(lambda image: \"Dogs\" in image, all_images))\n",
        "    all_cats = list(filter(lambda image: \"Cats\" in image, all_images))\n",
        "\n",
        "    index_to_split = int(len(all_dogs) - len(all_dogs) * validation_size)\n",
        "    training_dogs = all_dogs[:index_to_split]\n",
        "    validation_dogs = all_dogs[index_to_split:]\n",
        "    training_cats = all_cats[:index_to_split]\n",
        "    validation_cats = all_cats[index_to_split:]\n",
        "    os.makedirs(\"./sorted_annotations\",exist_ok=True)\n",
        "    shutil.rmtree(\"./sorted_annotations\")\n",
        "    os.makedirs(\"./sorted_annotations/train/dogs/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_annotations/train/cats/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_annotations/validation/dogs/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_annotations/validation/cats/\", exist_ok=True)\n",
        "\n",
        "    copy_annotations_to_dir(training_dogs, \"./sorted_annotations/train/dogs\")\n",
        "    copy_annotations_to_dir(validation_dogs, \"./sorted_annotations/validation/dogs\")\n",
        "    copy_annotations_to_dir(training_cats, \"./sorted_annotations/train/cats\")\n",
        "    copy_annotations_to_dir(validation_cats, \"./sorted_annotations/validation/cats\")\n",
        "\n",
        "def distribute_images_train_validation_split(validation_size=0.2):\n",
        "\n",
        "    all_images = os.listdir(\"./images\")\n",
        "\n",
        "    random.shuffle(all_images)\n",
        "\n",
        "    all_dogs = list(filter(lambda image: \"Dogs\" in image, all_images))\n",
        "    all_cats = list(filter(lambda image: \"Cats\" in image, all_images))\n",
        "\n",
        "    index_to_split = int(len(all_dogs) - len(all_dogs) * validation_size)\n",
        "    print(f\"dogs:{len(all_dogs)} \\ncats: {len(all_cats)}\")\n",
        "    training_dogs = all_dogs[:index_to_split]\n",
        "    validation_dogs = all_dogs[index_to_split:]\n",
        "    training_cats = all_cats[:index_to_split]\n",
        "    validation_cats = all_cats[index_to_split:]\n",
        "    os.makedirs(\"./sorted_images\",exist_ok=True)\n",
        "    shutil.rmtree(\"./sorted_images\")\n",
        "    os.makedirs(\"./sorted_images/train/dogs/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_images/train/cats/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_images/validation/dogs/\", exist_ok=True)\n",
        "    os.makedirs(\"./sorted_images/validation/cats/\", exist_ok=True)\n",
        "\n",
        "    copy_images_to_dir(training_dogs, \"./sorted_images/train/dogs\")\n",
        "    copy_images_to_dir(validation_dogs, \"./sorted_images/validation/dogs\")\n",
        "    copy_images_to_dir(training_cats, \"./sorted_images/train/cats\")\n",
        "    copy_images_to_dir(validation_cats, \"./sorted_images/validation/cats\")\n",
        "\n",
        "\n",
        "def copy_images_to_dir(images_to_copy, destination):\n",
        "    for image in images_to_copy:\n",
        "        #print(f\"copying: {image} to : {destination}\")\n",
        "        shutil.copyfile(f\"./images/{image}\", f\"{destination}/{image}\")\n",
        "def copy_annotations_to_dir(images_to_copy, destination):\n",
        "    for image in images_to_copy:\n",
        "        #print(f\"copying: {image} to : {destination}\")\n",
        "        shutil.copyfile(f\"./annotations/{image}\", f\"{destination}/{image}\")\n",
        "\n",
        "if(__name__==\"__main__\"):\n",
        "  distribute_images_train_validation_split(0.2)\n",
        "  distribute_annotations_train_validation_split(0.2)\n",
        "  \n",
        "  #print(\"abc\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs:2498 \n",
            "cats: 1188\n",
            "dogs:2498 \n",
            "cats: 1188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUcnupDaeYEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0eaf6f-ed8f-4374-f3c5-cf9c6b215e15"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug\n",
        "from scipy.io import loadmat\n",
        "import cv2\n",
        "import imageio\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "import re\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "\n",
        "\n",
        "def extract_mat_contents(annot_directory, image_dir):\n",
        "        \n",
        "        # Create MAT Parser\n",
        "        mat = loadmat(annot_directory,)\n",
        "\n",
        "        # Get the height and width for our image\n",
        "        height, width = cv2.imread(image_dir).shape[:2]\n",
        "\n",
        "        # Get the bounding box co-ordinates\n",
        "        x1, y2, y1, x2 = tuple(map(tuple, mat[\"box_coord\"]))[0]\n",
        "\n",
        "        # We Split the image Directory passed in the method and choose the index\n",
        "        # Of the Folders name which is the same as it\"s class\n",
        "        class_name = image_dir.split(\"/\")[2]\n",
        "\n",
        "        filename = \"/\".join(image_dir.split(\"/\")[-2:])\n",
        "\n",
        "        # Return the extracted attributes\n",
        "        return filename,  width, height, class_name, x1,y1,x2,y2\n",
        "\n",
        "def bounding_boxes_to_df(bounding_boxes_object):\n",
        "\n",
        "    # Convert Bounding Boxes Object to Array\n",
        "    bounding_boxes_array = bounding_boxes_object.to_xyxy_array()\n",
        "    \n",
        "    # Convert the array into DataFrame\n",
        "    df_bounding_boxes = pd.DataFrame(bounding_boxes_array, \n",
        "                                     columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
        "    \n",
        "    # Return the DataFrame\n",
        "    return df_bounding_boxes\n",
        "def mat_to_csv(annot_directory, image_directory, classes_folders):\n",
        "\n",
        "  # List containing all our attributes regarding each image\n",
        "  mat_list = []\n",
        "\n",
        "  # We loop our each class and its labels one by one to preprocess and augment \n",
        "  for class_folder in classes_folders:\n",
        "\n",
        "    # Set our images and annotations directory\n",
        "    image_dir = os.path.join(image_directory, class_folder)\n",
        "    annot_dir = os.path.join(annot_directory, class_folder) \n",
        "\n",
        "    # Get each file in the image and annotation directory\n",
        "    mat_files = sorted(os.listdir(annot_dir))\n",
        "    img_files = sorted(os.listdir(image_dir))\n",
        "\n",
        "    # Loop over each of the image and its label\n",
        "    for mat, image_file in zip(mat_files, img_files):\n",
        "      \n",
        "      # Full mat path\n",
        "      mat_path = os.path.join(annot_dir, mat)\n",
        "\n",
        "      # Full path Image\n",
        "      img_path = os.path.join(image_dir, image_file)\n",
        "\n",
        "      # Get Attributes for each image \n",
        "      value = extract_mat_contents(mat_path, img_path)\n",
        "\n",
        "      # Append the attributes to the mat_list\n",
        "      mat_list.append(value)\n",
        "\n",
        "  # Columns for Pandas DataFrame\n",
        "  column_name = [\"filename\", \"width\", \"height\", \"class\", \"xmin\", \"ymin\", \n",
        "                 \"xmax\", \"ymax\"]\n",
        "\n",
        "  # Create the DataFrame from mat_list\n",
        "  mat_df = pd.DataFrame(mat_list, columns=column_name)\n",
        "\n",
        "  # Return the dataframe\n",
        "  return mat_df\n",
        "# Function to convert MAT files to CSV\n",
        "\n",
        "\n",
        "# The Classes we will use for our training\n",
        "classes_list = sorted([\"dogs\",  \"cats\"])\n",
        "\n",
        "\n",
        "# Set our images and annotations directory\n",
        "image_directory = \"sorted_images/train\"\n",
        "annot_directory = \"sorted_annotations/train\"\n",
        "\n",
        "# Run the function to convert all the MAT files to a Pandas DataFrame\n",
        "labels_df = mat_to_csv(annot_directory, image_directory, classes_list)\n",
        "\n",
        "# Saving the Pandas DataFrame as CSV File\n",
        "labels_df.to_csv((\"labels.csv\"), index=None)\n",
        "\n",
        "# Function to convert bounding box image into DataFrame \n",
        "# Define all the Augmentations you want to apply to your dataset\n",
        "# We\"re setting random `n` agumentations to 2. \n",
        "image_augmentations = iaa.SomeOf( 2,\n",
        "    [                                 \n",
        "    # Scale the Images\n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "\n",
        "    # Rotate the Images\n",
        "    iaa.Affine(rotate=(-60, 60)),\n",
        "\n",
        "    # Shift the Image\n",
        "    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
        "\n",
        "    # Flip the Image\n",
        "    iaa.Fliplr(1),\n",
        "\n",
        "    # Increase or decrease the brightness\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "\n",
        "    # Add Gaussian Blur\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    \n",
        "    # Add Gaussian Noise\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "\n",
        "])\n",
        "def image_aug(df, images_path, aug_images_path, augmentor, multiple = 3):\n",
        "    all_Image=os.listdir(images_path)\n",
        "    pbar = tqdm(total=len(all_images)*multiple,position=0, leave=True)\n",
        "    # Fill this DataFrame with image attributes\n",
        "    augmentations_df = pd.DataFrame(\n",
        "        columns=[\"filename\",\"width\",\"height\",\"class\", \"xmin\", \"ymin\", \"xmax\",\n",
        "                 \"ymax\"])\n",
        "    \n",
        "    # Group the data by filenames\n",
        "    grouped_df = df.groupby(\"filename\")\n",
        "\n",
        "    # Create the directory for all augmentated images\n",
        "    if not os.path.exists(aug_images_path):\n",
        "      os.mkdir(aug_images_path)\n",
        "\n",
        "    # Create directories for each class of augmentated images\n",
        "    for folder in df[\"class\"].unique():\n",
        "      if not os.path.exists(os.path.join(aug_images_path, folder)):\n",
        "        os.mkdir(os.path.join(aug_images_path, folder))\n",
        "    \n",
        "    for i in range(multiple):\n",
        "      \n",
        "      # Post Fix we add to the each different augmentation of one image\n",
        "      image_postfix = str(i)\n",
        "      \n",
        "      # Loop to perform the augmentations\n",
        "      for filename in df[\"filename\"].unique():\n",
        "        pbar.update(1)\n",
        "        pbar.set_description(f\"Processing {filename}\")\n",
        "        augmented_path = os.path.join(aug_images_path, filename)+image_postfix+\".png\"\n",
        "\n",
        "        # Take one image at a time with its information\n",
        "        single_image = grouped_df.get_group(filename)\n",
        "        single_image = single_image.reset_index()\n",
        "        single_image = single_image.drop([\"index\"], axis=1)   \n",
        "        \n",
        "        # Read the image\n",
        "        image = imageio.imread(os.path.join(images_path, filename))\n",
        "\n",
        "        # Get bounding box\n",
        "        bounding_box_array = single_image.drop([\"filename\", \"width\", \"height\",\n",
        "                                                \"class\"], axis=1).values\n",
        "\n",
        "        # Give the bounding box to imgaug library\n",
        "        bounding_box = BoundingBoxesOnImage.from_xyxy_array(bounding_box_array, \n",
        "                                                            shape=image.shape)\n",
        "\n",
        "        # Perform random 2 Augmentations\n",
        "        image_aug, bounding_box_aug = augmentor(image=image, \n",
        "                                                bounding_boxes=bounding_box)\n",
        "        \n",
        "        # Discard the the bounding box going out the image completely   \n",
        "        bounding_box_aug = bounding_box_aug.remove_out_of_image()\n",
        "\n",
        "        # Clip the bounding box that are only partially out of th image\n",
        "        bounding_box_aug = bounding_box_aug.clip_out_of_image()\n",
        "\n",
        "        # Get rid of the the image if bounding box was discarded  \n",
        "        if re.findall(\"Image...\", str(bounding_box_aug)) == [\"Image([]\"]:\n",
        "            pass\n",
        "        \n",
        "        else:\n",
        "        \n",
        "          # Create the augmented image file\n",
        "          imageio.imwrite(augmented_path, image_aug) \n",
        "\n",
        "          # Update the image width and height after augmentation\n",
        "          info_df = single_image.drop([\"xmin\", \"ymin\", \"xmax\", \"ymax\"], axis=1)    \n",
        "          for index, _ in info_df.iterrows():\n",
        "              info_df.at[index, \"width\"] = image_aug.shape[1]\n",
        "              info_df.at[index, \"height\"] = image_aug.shape[0]\n",
        "\n",
        "          # Add the prefix to each image to differentiate if required\n",
        "          info_df[\"filename\"] = info_df[\"filename\"].apply(lambda x: x + image_postfix + \".jpg\")\n",
        "\n",
        "          # Create the augmented bounding boxes dataframe \n",
        "          bounding_box_df = bounding_boxes_to_df(bounding_box_aug)\n",
        "\n",
        "          # Concatenate the filenames, height, width and bounding boxes \n",
        "          aug_df = pd.concat([info_df, bounding_box_df], axis=1)\n",
        "\n",
        "          # Add all the information to augmentations_df we initialized above\n",
        "          augmentations_df = pd.concat([augmentations_df, aug_df])\n",
        "              \n",
        "              \n",
        "      \n",
        "    # Remove index\n",
        "    augmentations_df = augmentations_df.reset_index()\n",
        "    augmentations_df = augmentations_df.drop([\"index\"], axis=1)\n",
        "\n",
        "    # Return the Dataframe\n",
        "    pbar.finish()\n",
        "    return augmentations_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "augmented_images_df = image_aug(labels_df, image_directory, \"aug_images\", \n",
        "                                image_augmentations)\n",
        "\n",
        "augmented_images_df = augmented_images_df.sort_values(\"filename\", ignore_index= True)\n",
        "augmented_images_df.to_csv(\"aug.csv\")\n",
        "\n",
        "# Check Dataset Size\n",
        "print(\"Our total dataset Size before the augmentations was: \", len(labels_df))\n",
        "print(\"Our total dataset Size after the augmentations is: \", len(augmented_images_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing cats/Cats_Test1017.png:   0%|          | 12/11058 [00:04<1:17:28,  2.38it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}